{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1cd48e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/joythompson/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/joythompson/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "from pandas import DataFrame\n",
    "import itertools\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import requests\n",
    "import random\n",
    "import torch\n",
    "import xmltodict\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml\n",
    "from xml.etree.ElementTree import parse\n",
    "from xml.parsers import expat\n",
    "from xml.dom.minidom import parse, parseString\n",
    "import psycopg2\n",
    "import PyPDF2\n",
    "import pikepdf\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b39c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createfiledirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cdfb02",
   "metadata": {},
   "source": [
    "# **LOAD & TRANSFORM BILL XML DATA FROM LOCAL FILE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "343ff377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findheaderword(headers):\n",
    "    verbspd=pd.DataFrame(columns=['BillID', 'HeaderID', 'HeaderOrderID','EntityOrderID', 'Text','PartofSpeech', 'SubjObjPred', 'HeadText']);\n",
    "    billidlist=[];\n",
    "    nlp = spacy.load(\"en_core_web_sm\");\n",
    "    for ind in headers.index:\n",
    "    \n",
    "        doc = nlp(headers.loc[ind,'Text'].replace('-', ' ').replace('     ', '')) ;\n",
    "        span = doc[doc[len(doc)-1].left_edge.i : doc[len(doc)-1].right_edge.i+1];\n",
    "        entorder=0 ;\n",
    "        with doc.retokenize() as retokenizer:\n",
    "            retokenizer.merge(span);\n",
    "            for token in doc:\n",
    "                entorder=entorder+1;\n",
    "                verbspd=verbspd.append({ 'BillID': headers.loc[ind, 'BillID'], 'HeaderID': headers.loc[ind, 'HeaderID'],\n",
    "                            'HeaderOrderID': headers.loc[ind, 'HeaderOrderID'],'EntityOrderID':entorder, 'Text':token.text,\n",
    "                                           'PartofSpeech':token.pos_, 'SubjObjPred': token.dep_, 'HeadText':token.head.text},ignore_index=True);\n",
    "        if str(headers.loc[ind, 'BillID'])[-1]=='0' and headers.loc[ind, 'BillID'] not in billidlist:\n",
    "            billidlist.append(headers.loc[ind, 'BillID']);\n",
    "            print(headers.loc[ind, 'BillID']);\n",
    "    return verbspd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5b8348",
   "metadata": {},
   "source": [
    "# **EXECUTE DATA IMPORT & TRANSFORM FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c630914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "username='joythompson'\n",
    "projfol=\"/Users/\"+username+\"/Desktop/DSE_203_JoyT/DSE_203_Final_Project_JoyT/\"\n",
    "directorybillhead=createfiledirectory(projfol+ 'Bill_Parsing_Headers/')\n",
    "headerpd=pd.read_csv(directorybillhead+ 'header_text_by_bill_header_with_order.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7b6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "30\n",
      "70\n",
      "80\n",
      "120\n",
      "150\n",
      "160\n",
      "170\n",
      "190\n",
      "200\n",
      "210\n",
      "230\n",
      "240\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n"
     ]
    }
   ],
   "source": [
    "verbspd=findheaderword(headerpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798024e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbspd.to_csv(directorybillhead+ 'bill_obj_action_subj_by_bill_header.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c53f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD CSV WITH HEADERS FROM \"https://github.com/JoyT10294/DSE203_FinalProj/blob/main/polirepsdata.csv\" AS repdata\n",
    "CREATE (politician:Politician {id: repdata.representativeid, lastname: repdata.lastname, firstname: repdata.firstname})\n",
    "CREATE (state:State {id: repdata.statecode, name: repdata.statelabel})\n",
    "\n",
    "CREATE (politician)-[:REPRESENTS {district:repdata.district}]->(state)\n",
    "CREATE (party:Party {name: repdata.party})\n",
    "CREATE (politician)-[:MEMBER_OF]->(party)\n",
    "CREATE (chamber:Chamber {name: repdata.chamber})\n",
    "CREATE (politician)-[:SERVES_IN]->(chamber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169bf9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD CSV WITH HEADERS FROM \"https://github.com/JoyT10294/DSE203_FinalProj/blob/main/polirepsdata.csv\" AS repdata\n",
    "CREATE (politician:Politician {id: , lastname:, firstname: })\n",
    "CREATE CONSTRAINT ON (politician:Politician) ASSERT politician.id IS UNIQUE\n",
    "CREATE CONSTRAINT ON (politician:Politician) ASSERT exists(politician.id)\n",
    "CREATE (state:State {id: , name:})\n",
    "CREATE CONSTRAINT ON (state:State) ASSERT state.id IS UNIQUE\n",
    "CREATE CONSTRAINT ON (state:State) ASSERT exists(state.id)\n",
    "CREATE (politician)-[:REPRESENTS {district:repdata.district}]->(state)\n",
    "CREATE (party:Party {name: repdata.party})\n",
    "CREATE (politician)-[:MEMBER_OF]->(party)\n",
    "CREATE (chamber:Chamber {name: repdata.chamber})\n",
    "CREATE (politician)-[:SERVES_IN]->(chamber)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
