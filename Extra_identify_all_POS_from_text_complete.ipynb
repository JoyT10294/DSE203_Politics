{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1cd48e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/joythompson/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/joythompson/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "from pandas import DataFrame\n",
    "import itertools\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import requests\n",
    "import random\n",
    "import torch\n",
    "import xmltodict\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml\n",
    "from xml.etree.ElementTree import parse\n",
    "from xml.parsers import expat\n",
    "from xml.dom.minidom import parse, parseString\n",
    "import psycopg2\n",
    "import PyPDF2\n",
    "import pikepdf\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b39c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createfiledirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cdfb02",
   "metadata": {},
   "source": [
    "# **LOAD & TRANSFORM BILL XML DATA FROM LOCAL FILE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202112d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findkeyword(headers):\n",
    "    tokenpd=pd.DataFrame(columns=['BillID', 'HeaderID', 'HeaderOrderID','EntityOrderID', 'Text','De-Conjugate', 'POS Descr', 'POS', 'POS Text', 'Caps'])\n",
    "    keeplist=['no', 'some', 'all','every','each', 'any', 'after', 'before'];\n",
    "    dellist= ['DET', 'ADP', 'CCONJ', 'PUNCT', 'SPACE'] ;\n",
    "    nlp = spacy.load(\"en_core_web_sm\");\n",
    "    billidlist=[];\n",
    "    for ind in headers.index:\n",
    "        doc = nlp(headers.loc[ind,'Text'].replace('-', ' ').replace('     ', '')) ;\n",
    "        entorder=0;\n",
    "        for token in doc:\n",
    "            if (token.pos_ not in dellist or  str(token.text).lower() in keeplist) :\n",
    "                entorder=entorder+1;\n",
    "                tokenpd=tokenpd.append({ 'BillID': headers.loc[ind, 'BillID'], 'HeaderID': headers.loc[ind, 'HeaderID'],\n",
    "                            'HeaderOrderID': headers.loc[ind, 'HeaderOrderID'],'EntityOrderID':entorder, 'Text':token.text, 'De-Conjugate': token.lemma_,\n",
    "                            'POS Descr':token.pos_,  'POS':token.tag_, 'POS Text':token.dep_, 'Caps':token.shape_},ignore_index=True);\n",
    "        if str(headers.loc[ind, 'BillID'])[-1]=='0' and headers.loc[ind, 'BillID'] not in billidlist:\n",
    "            billidlist.append(headers.loc[ind, 'BillID']);\n",
    "            print(headers.loc[ind, 'BillID']);\n",
    "    return tokenpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5b8348",
   "metadata": {},
   "source": [
    "# **EXECUTE DATA IMPORT & TRANSFORM FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c630914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "username='joythompson'\n",
    "projfol=\"/Users/\"+username+\"/Desktop/DSE_203_JoyT/DSE_203_Final_Project_JoyT/\"\n",
    "directorybillhead=createfiledirectory(projfol+ 'Bill_Parsing_Headers/')\n",
    "headerpd=pd.read_csv(directorybillhead+ 'header_text_by_bill_header_with_order.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb4370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "30\n",
      "70\n",
      "80\n",
      "120\n",
      "150\n",
      "160\n",
      "170\n",
      "190\n",
      "200\n",
      "210\n",
      "230\n",
      "240\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n"
     ]
    }
   ],
   "source": [
    "tokenpd=findkeyword(headerpd)\n",
    "tokenpd.to_csv(directorbillhead+ 'header_part_speech_text_by_bill_header_with_order.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
